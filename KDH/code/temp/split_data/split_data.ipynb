{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad28c23b-d8e5-4461-adea-f281885f72a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from split_data import split_data\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ffa77c-3157-40d2-b46a-097a2d6d1a25",
   "metadata": {},
   "source": [
    "# How to use\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071ef128-c7a0-4951-b1f2-3f583ae0a499",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:20px; color:red;\">dataset 폴더에 split_data.ipynb 와 split_data.py 를 같이 넣어주세요</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62839f31-fab7-4642-bd1f-52528e93972f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Structure \n",
    "---\n",
    "### split_data.py\n",
    "* #### split_data\n",
    "    * load_json\n",
    "    * sorting_data\n",
    "    * classify_image\n",
    "    * init_dataset\n",
    "    * split_data_local\n",
    "    * split_base_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b090c3-a140-4ef1-ba3a-b5dea4249477",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### split_data(\n",
    "#### train_ratio:float=0.8, -> train 데이터의 비율\n",
    "#### exclude:bool=False, -> miss labeled data 를 제외할지 여부\n",
    "#### excluded_id:list=[], -> 제외할 data\n",
    "#### file_path:str='train.json', -> 쪼갤 데이터\n",
    "#### licence:bool=False) -> json file 에 licence 와 info 를 포함할지 여부\n",
    "#### -> list:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad0ba0-771e-4f6b-95ab-8e3454e25a9a",
   "metadata": {},
   "source": [
    "# progress start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dfa6afe-cacf-4ecb-b78a-bd2b4cda72c8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Load [/opt/ml/dataset/train.json] complete |\n",
      "\n",
      "| Excluding start |\n",
      "| Excluding end |\n",
      "\n",
      "| image classify start |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [00:12<00:00, 403.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| image classify end |\n",
      "\n",
      "| data split start |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:00, 5326.46it/s]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_list length : 46\n",
      "train_list length : 38\n",
      "valid_list length : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "228it [00:00, 7458.23it/s]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_list length : 227\n",
      "train_list length : 189\n",
      "valid_list length : 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "631it [00:00, 9198.35it/s]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_list length : 630\n",
      "train_list length : 525\n",
      "valid_list length : 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "526it [00:00, 11123.57it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_list length : 525\n",
      "train_list length : 437\n",
      "valid_list length : 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "264it [00:00, 12264.59it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_list length : 263\n",
      "train_list length : 219\n",
      "valid_list length : 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "378it [00:00, 13872.02it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_list length : 377\n",
      "train_list length : 314\n",
      "valid_list length : 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "792it [00:00, 19369.73it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_list length : 791\n",
      "train_list length : 659\n",
      "valid_list length : 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "992it [00:00, 33284.13it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_list length : 991\n",
      "train_list length : 825\n",
      "valid_list length : 166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "651it [00:00, 67629.96it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_list length : 650\n",
      "train_list length : 541\n",
      "valid_list length : 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "384it [00:00, 167929.59it/s]           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_list length : 383\n",
      "train_list length : 319\n",
      "valid_list length : 64\n",
      "\n",
      "| data split end |\n",
      "\n",
      "| make train_set start |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4066/4066 [00:06<00:00, 651.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| make train_set end |\n",
      "\n",
      "| make valid_set start |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 817/817 [00:01<00:00, 644.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| make valid_set end |\n",
      "\n",
      "| process success |\n"
     ]
    }
   ],
   "source": [
    "# split_data(train_ratio=0.8, exclude=True, excluded_id=[num for num in range(0, 4000, 100)], file_path='/opt/ml/dataset/train.json', licence=False)\n",
    "split_data(train_ratio=0.8, exclude=True, file_path='/opt/ml/dataset/train.json', licence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b20d4577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train.json annot : 23144\n",
      "length of train.json image : 4883\n",
      "\n",
      "length of train_set.json annot : 19032\n",
      "length of train_set.json image : 4066\n",
      "\n",
      "length of valid_set.json annot : 4112\n",
      "length of valid_set.json image : 817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in ['train.json', 'train_set.json', 'valid_set.json']:\n",
    "    with open ('/opt/ml/dataset/' + file, 'r') as base_data:\n",
    "        json_file = json.load(base_data)\n",
    "        print(f'length of {file} annot : {len(json_file[\"annotations\"])}')\n",
    "        print(f'length of {file} image : {len(json_file[\"images\"])}')  \n",
    "        print('')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
